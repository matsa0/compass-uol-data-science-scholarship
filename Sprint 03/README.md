
<h1 align="center">
    <strong>SPRINT 03</strong>
</h1>

# üìù Exerc√≠cios

No diret√≥rio de exerc√≠cios, coloquei alguns noteboooks que eu trabalhei durante o curso.

# üî¥ V√≠deo - [Desafio Sprint 03](https://compasso-my.sharepoint.com/:v:/g/personal/matheus_azevedo_pb_compasso_com_br/Efb0dNQWhMBJiovzgamlg0YBp9K82x4rAuVNhYSBLM73lA?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=kiOe7W)


# üîé Evid√™ncias

### ‚û£ Curso: Forma√ß√£o Completa Intelig√™ncia Artificial e Machine Learning

- **Se√ß√£o 2: Fundamentos de Machine Learning**<br>
    'Fundamentos de Machine Learning' √© uma se√ß√£o completamente te√≥rica que nos introduz conceitos que s√£o abordados durante todo o curso em diferentes momentos. O que √© **machine learning**, sua **aplicabilidade** em diferentes √°reas, **dados**, **modelos**, **classifica√ß√£o**, **regress√£o**, **associa√ß√£o**, **agrupamentos**, **performance**, entre outros.

    - Quiz da se√ß√£o:

        ![Evid√™ncia](./evidencias/sec2/quiz_sec2.png)


- **Se√ß√£o 3: Estudo de Algoritmos de Machine Learning**<br>
    Na se√ß√£o 3 aprendemos diferentes algoritmos em machine learning, o que se precisa para cri√°-los, medir sua performance e otimiz√°-los. Abaixo, tem-se exemplos de como foram trabalhados alguns algoritmos nessa se√ß√£o.

    - **Cria√ß√£o do modelo de regress√£o linear:**<br> Divis√£o de vari√°vel dependente(a que queremos prever) e vari√°veis independentes(que v√£o auxiliar na previs√£o). 

        ![Evid√™ncia](./evidencias/sec3/criacao_modelo_regressao_1.png)
    
    
    - **Sele√ß√£o de vari√°veis:**<br> Antes de realizar o treinamento de um modelo machine learning, √© necess√°rio selecionar as vari√°vel que se utilizar√°. A vari√°vel **dependente** representa a que queremos que o modelo realize previs√µes, as **independentes** s√£o as que ir√£o auxiliar o modelo a realizar correla√ß√µes para a previs√£o.

     - **Transforma√ß√£o de dados:**<br> Um modelo machine learning n√£o √© capaz de entender vari√°veis categ√≥ricas, portanto, √© necess√°rio realizar uma transforama√ß√£o de vari√°veis categ√≥ricas para n√∫mericas. O `LabelEncoder` faz esse trabalho tranformando vari√°veis do tipo `object` em n√∫meros, dessa forma o modelo consegue compreender, realizar associa√ß√µes e aprender.

        ![Evidencia](./evidencias/sec3/transformacao_dados.png)

    - **Treinamento de um modelo Naive Bayes:**<br> O algoritmo Naive Bayes √© um classificador probabil√≠stico baseado no `Teorema de Bayes`. √â amplamente utilizado em tarefas de classifica√ß√£o como an√°lise de sentimentos, detec√ß√£o de spam e categoriza√ß√£o de texto. Nesse caso, utiliza-se o modelo `Gaussian Naive Bayes (GaussianNB)`. Nele fazemos a prepara√ß√£o e transforma√ß√£o dos dados de entrada, divis√£o entre conjunto de treinamento e teste, ajuste do modelo ao conjunto de treinamento usando o m√©todo `fit()` e por fim, a previs√£o de r√≥tulos com o m√©todo `predict()`.     

        ![Evid√™ncia](./evidencias/sec3/treinando_modelo_naive_bayes.png)

    - **Analisando performance atrav√©s de m√©tricas:**<br> As m√©tricas de desempenho s√£o muito importantes para avaliar a performance de um modelo machine learning. As principais s√£o `acur√°cia`, `precis√£o`, `recall` e `f1-score`. Cada m√©trica tem uma f√≥rmula tem sua particularidade atrav√©s de uma f√≥rmula bem definida.

        ![Evidencia](./evidencias/sec3/analise_performance_nayve_bayes.png)

    - **Arvore de decis√£o:**<br> O algoritmo de √°rvore de decis√£o utiliza uma estrutura hier√°rquica para dividir os dados em subconjuntos com base em condi√ß√µes de decis√£o. Ele √© usado tanto para **classifica√ß√£o** quanto para **regress√£o**, sendo f√°cil de interpretar e visualizar quando seus par√¢metros s√£o tratados corretamente.

        ![Evidencia](./evidencias/sec3/arvore_decisao.png)

        ![Evidencia](./evidencias/sec3/arvore_geradaa.png)

    - **Aprendizado baseado em inst√¢ncia:**<br> No aprendizado baseado em inst√¢ncia, o modelo aprende armazenando os exemplos de treinamento e faz previs√µes com base nesses exemplos. O **KNN (K-Nearest Neighbors)** √© um dos algoritmos dessa categoria que classifica uma amostra ao observar os K exemplos mais pr√≥ximos no conjunto de treinamento, usando uma m√©trica de dist√¢ncia, como a Euclidiana.

        ![Evidencia](./evidencias/sec3/knn_mais_proximo_1.png)

        ![Evidencia](./evidencias/sec3/knn_mais_proximo_2.png)

    - **Clusters diversos:**<br> O agrupamento(`clustering`) √© uma t√©cnica de aprendizado **n√£o supervisionado** que busca identificar padr√µes ou grupos em dados n√£o rotulados. Os algoritmos de clustering t√™m diversas aplica√ß√µes, como an√°lise de comportamento de clientes, segmenta√ß√£o de mercado e detec√ß√£o de anomalias.

        - **Kmeans:**<br> Divide os dados em K grupos, onde cada ponto pertence ao cluster cujo centro est√° mais pr√≥ximo

            ![Evidencia](./evidencias/sec3/kmeans.png)

            ![Evidencia](./evidencias/sec3/kmeans_cluster.png)
        
        - **Dbscam:**<br> Algoritmo baseado em densidade que forma clusters conectando pontos em regi√µes densas

            ![Evidencia](./evidencias/sec3/dbscam_cluster.png)

    - **Regras de associa√ß√£o - Apriori:**<br>  O Apriori tamb√©m √© um algoritmo **n√£o supervisionado** que identifica rela√ß√µes frequentes entre vari√°veis em bases de dados. Ele se baseia no princ√≠pio de que todos os subconjuntos de um item frequente tamb√©m devem ser frequentes. Isso reduz significativamente a busca em grandes datasets.

        ![Evidencia](./evidencias/sec3/apriori.png)


        ![Evidencia](./evidencias/sec3/transformacao_dados.png)


- **Se√ß√£o 4: T√≥picos Avan√ßados em Machine Learning**<br>
    A se√ß√£o 4 nos permitiu uma abordagem mais avan√ßada dos t√≥picos de machine learning, onde diversos conceitos foram trabalhados de forma densa, como: engenharia e sele√ß√£o de atributos, avalia√ß√£o de variabilidade, custo e desempenho de um modelo, t√©cnicas mais avan√ßadas de clusteriza√ß√£o, entre outros.

    - **Engenharia de atributos:**<br> O tratamento inicial de dados com a engenharia de atributos √© essencial para limpar e transformar dados, garantindo que estejam prontos para o aprendizado.

        ![Evidencia](./evidencias/sec4/valores_faltantes_1.png) 

        ![Evidencia](./evidencias/sec4/valores_faltantes_2.png)

        ![Evidencia](./evidencias/sec4/outliers.png)   

        - **Data Binning:**<br> T√©cnica para agrupar valores cont√≠nuos em intervalos (bins), facilitando an√°lises.

            ![Evidencia](./evidencias/sec4/data_binning.png)

         - **Label Encoder:**<br> O Label Encoder √© uma t√©cnica de codifica√ß√£o que transforma vari√°veis categ√≥ricas em valores num√©ricos inteiros.
            ![Evidencia](./evidencias/sec4/label_encoder.png)

        - **One Hot Encoder:**<br> Transforma vari√°veis categ√≥ricas em representa√ß√µes bin√°rias para uso em modelos de machine learning, criando uma coluna distinta para cada categoria. 
            ![Evidencia](./evidencias/sec4/one_hot_encoder_1.png)

        - **Standard Scalar:**<br> Normaliza os dados para padronizar as vari√°veis com m√©dias pr√≥ximas de zero e desvio padr√£o unit√°rio, otimizando o desempenho dos algoritmos.

            ![Evidencia](./evidencias/sec4/one_hot_encoder_2.png)

    - **Sele√ß√£o de atributos:**<br> Selecionar os atributos certos melhora a efici√™ncia do modelo e reduz o risco de overfitting. T√©cnicas de sele√ß√£o ajudam a identificar as vari√°veis mais relevantes para o problema em quest√£o.

        ![Evidencia](./evidencias/sec4/selecao_atributos_1.png)

        ![Evidencia](./evidencias/sec4/selecao_atributos_2.png)

    - **Compara√ß√£o de melhores agrupadores clusters (KMeans, Agglomerative e DBSCAN):**<br>

        ![Evidencia](./evidencias/sec4/melhor_agrupador_cluster.png)

        ![Evidencia](./evidencias/sec4/melhor_agrupador_cluster_2.png)

    - **Antes e depois do modelo de transforma√ß√£o:**<br>

        ![Evidencia](./evidencias/sec4/modelo_transformacao_1.png)

        ![Evidencia](./evidencias/sec4/modelo_transformacao_2.png)

- **Se√ß√£o 5: Redes Neurais, Deep Learning e Computer Vision**<br>
    A se√ß√£o 5 introduz e aprofunda os conceitos de `Redes Neurais Artificiais(RNA)`. Aprendi sobre o funcionamento de modelos como Perceptron, redes MLP (Perceptron Multicamadas), Redes Neurais Convolucionais (CNN), redes recorrentes como LSTM, al√©m de conceitos como Autoencoders para aprendizado n√£o supervisionado. 

    - **Implementando uma Rede Neural MLP:**<br> MLP √© uma rede neural com pelo menos uma camada oculta que realiza **aprendizado supervisionado** para classifica√ß√£o ou regress√£o. Aprendemos a configurar os hiperpar√¢metros, como n√∫mero de camadas, neur√¥nios, taxa de aprendizado e fun√ß√£o de ativa√ß√£o, e analisamos o desempenho do modelo monitorando m√©tricas como a taxa de perda (`loss rate`).

        ![Evidencia](./evidencias/sec5/definicao_hiperparametros.png)

        ![Evidencia](./evidencias/sec5/visualizando_loss_rate.png)

    - **Implementando RNA com Keras:**<br> `Keras` √© uma biblioteca de alto n√≠vel para constru√ß√£o e treinamento de redes neurais, facilitando a cria√ß√£o de modelos complexos. 

        ![Evidencia](./evidencias/sec5/rna_keras_1.png)

        ![Evidencia](./evidencias/sec5/rna_keras_2.png)

        ![Evidencia](./evidencias/sec5/rna_keras_3.png)

        ![Evidencia](./evidencias/sec5/rna_keras_4.png)

    - **CNN:**<br> As `CNNs` s√£o redes especialmente projetadas para tarefas de **vis√£o computacional**, como classifica√ß√£o de imagens, detec√ß√£o de objetos e segmenta√ß√£o. Utilizam camadas convolucionais para extrair padr√µes espaciais e caracter√≠sticas relevantes das imagens.

        ![Evidencia](./evidencias/sec5/cnn_1.png)

        ![Evidencia](./evidencias/sec5/cnn_2.png)

    - **Autoencoders:**<br> Autoencoders s√£o redes neurais projetadas para aprender representa√ß√µes compactas e √∫teis dos dados de entrada, utilizando aprendizado n√£o supervisionado. Muito utilizados para redu√ß√£o de dimensionalidade, detec√ß√£o de anomalias entre outros.

        ![Eviencia](./evidencias/sec5/autoencoder.png)

- **Se√ß√£o 6: Machine Learning Explic√°vel**<br>
    Essa se√ß√£o aborda o conceito de `Machine Learning Explic√°vel (Explainable AI - XAI)`, um ramo da IA que se concentra em tornar os modelos mais interpret√°veis e transparentes, permitindo aos usu√°rios compreender como as decis√µes s√£o tomadas. 

    - **XAI - Eli5:**<br> O `Eli5` √© uma biblioteca Python que fornece explica√ß√µes intuitivas para modelos de machine learning. Ele permite visualizar o impacto de diferentes features no resultado de modelos, como √°rvores de decis√£o, regress√£o log√≠stica e outros, ajudando a identificar quais atributos t√™m maior peso nas decis√µes

        ![Evidencia](./evidencias/sec6/xai_eli5.png)

    - **Shap - Atributos que influenciam bom e mal pagador:**<br> O `SHAP (SHapley Additive exPlanations)` √© uma t√©cnica avan√ßada que utiliza valores de Shapley para calcular a contribui√ß√£o de cada atributo em uma predi√ß√£o. No contexto de an√°lise de cr√©dito, aprendemos a identificar os fatores que mais influenciam as decis√µes relacionadas a bons e maus pagadores.

        ![Evidencia](./evidencias/sec6/shap.png)

- **Se√ß√£o 7: Processamento de Linguagem Natural(NLP) e Large Language Models(LLMs)**<br> 
Essa se√ß√£o explora as bases do **Processamento de Linguagem Natural (NLP)**, apresentando t√©cnicas e ferramentas fundamentais para an√°lise de texto e introduzindo modelos de **linguagem de grande escala (LLMs)**, que revolucionaram o campo com sua capacidade de entender e gerar texto de forma contextual.

    - **Introdu√ß√£o a NLTK:**<br> A biblioteca NLTK (Natural Language Toolkit) √© amplamente utilizada em tarefas de NLP. Abordamos conceitos como:

        `Steaming:` Redu√ß√£o das palavras √†s suas ra√≠zes.<br>
        `Tokenize:` Divis√£o de textos em senten√ßas ou palavras.<br>
        `Stop Words:` Remo√ß√£o de palavras comuns sem valor sem√¢ntico relevante.<br>
        `Distribui√ß√£o de frequ√™ncia:` Identifica√ß√£o das palavras mais frequentes.<br>
       ` Entidades nomeadas:` Reconhecimento de nomes, datas e organiza√ß√µes no texto.

        ![Evidencia](./evidencias/sec7/nltk1.png)

        ![Evidencia](./evidencias/sec7/nltk2.png)

    - **Fillmask:**<br> T√©cnica utilizada para preencher lacunas em textos utilizando modelos de linguagem pr√©-treinados, permitindo an√°lises contextuais e gera√ß√£o de texto coerente.

        ![Evidencia](./evidencias/sec7/fillmask.png)

    - **OpenAI:**<br> Explora√ß√£o de APIs da OpenAI para gera√ß√£o de texto, tradu√ß√£o, resumo e outras tarefas de NLP. A pr√°tica incluiu a utiliza√ß√£o de modelos como o GPT para resolver problemas reais de linguagem.

        ![Evidencia](./evidencias/sec7/openai.png)


- **Se√ß√£o 9: Detec√ß√£o de Anomalias**<br> Nesta se√ß√£o, exploramos t√©cnicas para detectar **padr√µes an√¥malos em dados**, uma tarefa cr√≠tica em cen√°rios como detec√ß√£o de fraudes, monitoramento de sistemas e an√°lise preditiva. Aprendemos sobre m√©todos estat√≠sticos, densidade e modelos avan√ßados de deep learning.

    - **ZScore:**<br> O m√©todo `Z-Score` utiliza estat√≠sticas para identificar anomalias ao calcular a dist√¢ncia de um dado em rela√ß√£o √† m√©dia em termos de desvio padr√£o. √â √∫til para detectar valores extremos em dados num√©ricos.

        ![Evidencia](./evidencias/sec9/zscore.png)

    - **LOF(Local Outlier Factor):**<br> O algoritmo **LOF** detecta anomalias com base na densidade local, comparando a densidade de um ponto com a densidade de seus vizinhos. √â eficaz para detectar anomalias em conjuntos de dados com clusters variados.

        ![Evidencia](./evidencias/sec9/lof.png)

    - **LSTMAnomalias:**<br> O uso de **LSTMs (Long Short-Term Memory)** para detec√ß√£o de anomalias √© uma abordagem avan√ßada que explora padr√µes temporais em dados sequenciais. √â particularmente √∫til em s√©ries temporais, como monitoramento de sensores ou transa√ß√µes financeiras.

        ![Evidencia](./evidencias/sec9/lstmanomalias.png)

# üë®üèº‚Äçüéì Certificados

- Certificado do Curso **Forma√ß√£o Completa Intelig√™ncia Artificial e Machine Learning**

    ![Certificado](./certificados/formacao_completa_inteligencia_artificial_machine_learning.jpg)