
<h1 align="center">
    <strong>SPRINT 07</strong>
</h1>

# üîó V√≠deo - [Desafio Sprint 07]()


# üìù Exerc√≠cios

## üß† Curso: Credit Risk Modeling in Python

### Section 1: Introduction

### Section 2: Setting up the working enviroment

### Section 3: Dataset description

### Section 4: General preprocessing

### Section 5: PD model: Data Preparation

### Section 6: PD model estimation

### Section 7: PD model validation

### Section 8: Applying the PD model for decision making

### Section 9: PD model monitoring

### Section 10: LGD and EAD models: Preparing the data

### Section 11: LGD model

### Section 12: EAD model

### Section 13: Calculating expected loss


## üß† Curso: Amazon Bedrock, Amazon Q & AWS Generative AI

### Section 2: Basics of AI, ML & Neural Networks

### Section 3: Generative AI & Foundation Models Concepts

### Section 4: Amazon Bedrock - Deep Dive

### Section 5: Enterprise Use Case 1: Image Generation 

### Section 6: Enterprise Use Case 2: Text Summarization

### Section 7: Use Case 3: Building a Chatbot

### Section 8: Overview of Vectors & Embeddings

### Section 9: Use Case 4: Building HR Q&A




# üîé Evid√™ncias

## üß† Curso: Credit Risk Modeling in Python

### Section 1: Introduction

### Section 2: Setting up the working enviroment

### Section 3: Dataset description

### Section 4: General preprocessing

### Section 5: PD model: Data Preparation

### Section 6: PD model estimation

### Section 7: PD model validation

### Section 8: Applying the PD model for decision making

### Section 9: PD model monitoring

### Section 10: LGD and EAD models: Preparing the data

### Section 11: LGD model

### Section 12: EAD model

### Section 13: Calculating expected loss



## üß† Curso: Amazon Bedrock, Amazon Q & AWS Generative AI

### Section 2: Basics of AI, ML & Neural Networks
A se√ß√£o 2 foi interessante de ser realizada para a recorda√ß√£o de importantes conceitos que vemos durante a trilha relacionados Intelig√™ncia Artificial(AI), Machine Learning(ML), Deep Learning(DL) e Generative AI.

- **Aprendizado supervisionado**: modelos s√£o treinados utilizando **datasets rotulados**. O objetivo √© que o modelo aprenda a mapear as entradas para as sa√≠das corretas e consiga fazer previs√µes para novos dados. Esse tipo de aprendizado √© utilizando para resolver problemas de **classifica√ß√£o** e **regress√£o**.

- **Aprendizado n√£o supervisionado**: o algoritmo √© treinado utilizando **datasets n√£o rotulados**. Baseado no conjunto de dados, o modelo consegue encontrar padr√µes escondidos e insights baseados nas similaridades dos dados. Esse tipo de aprendizado √© muito utilizado em problemas de **clusteriza√ß√£o** e **redu√ß√£o de dimensionalidade**.

- **Deep Learning**: sub√°rea de Machine Learning que utiliza redes neurais profundas para **aprender representa√ß√µes complexas dos dados**. O treinamento dessas redes exige grandes volumes de dados e alto poder computacional. Muito utilizado para **reconhecimento de imagens** e **processamento de linguagem natural**.

- **IA Generativa**: sub√°rea de Deep Learning que foca em criar modelos capazes de **gerar conte√∫do** a partir de padr√µes aprendidos. Por exemplo, pode-se ter IA's generativas baseadas em texto, imagens, v√≠deos, a√∫dios, c√≥digo, entre outros. ChatGPT, DeepSeek, MidJourney s√£o exemplos de IA's generativas.

### Section 3: Generative AI & Foundation Models Concepts
Nesta se√ß√£o 3, a gente vai um pouco mais fundo no conceito de IA Generativa.

Utilizando o **Chat/Text playground** do `Claude 3 Haiku`, eu perguntei "O que √© uma IA Generativa?", e ela me retornou a seguinte resposta:

![Evidencia](./evidencias/curso_amazon_bedrock/sec3/ia_generativa.png)

Uma IA Generativa funciona atrav√©s de um `modelo fundamental`, que √© o modelo treinado com um grande conjunto de dados para capturar padr√µes gerais. 

A IA √© utilizada atrav√©s de um `prompt`, que significa a entrada do usu√°rio, podendo ser um texto, uma imagem, v√≠deo ou a√∫dio, contendo uma instru√ß√£o do usu√°rio para a IA.

O processamento do prompt fornecido pelo usu√°rio √© realizado pela IA para analisar o prompt e prever uma melhor resposta com base no que aprendeu no treinamento. Esse proceso √© chamado de `infer√™ncia`, e a resposta gerada, √© chamada de `completion`.

Ap√≥s receber um prompt, a IA realiza o proceso de `tokeniza√ß√£o`, que transforma o prompt em tokens num√©ricos, al√©m disso, ela deve levar em conta a janela de contexto(`context window`), que define quantos tokens o modelo pode levar em considera√ß√£o para dar uma resposta. O `detokenizer` reconverte os tokens para palavras, para gerar o completion.

√â importante compreender 3 conceitos de modelos fundamentais.

- **Tokens**: um token geralmente corresponde a 4 caracteres de texto.
- **Parameters**- n√∫meo de conex√µes e pesos entre n√≥s em uma rede neural.
- **Temperature** - par√¢metro que controla a criatividade e diversidade do modelo.

Exemplo de resposta do modelo `Llama` da Meta para o prompt *"Qual √© o melhor jogador de todos os tempos?"*, com par√¢metros como **Temperature** e **Top P** ajustados.

![Evidencia](./evidencias/curso_amazon_bedrock/sec3/chat_llama.png)

Outro caso de uso de IA Generativa, √© a **gera√ß√£o de imagens**, como no exemplo abaixo, onde utilizei o modelo `Titan Image Generator` da Amazon e coloquei um o prompt: *"Um gato fazendo exerc√≠cios na academia"*. A IA me retornou a imagem abaixo:

![Evidencia](./evidencias/curso_amazon_bedrock/sec3/Um%20gato%20fazendo%20exerc√≠cios%20na%20academia.png)

### Section 4: Amazon Bedrock - Deep Dive
Na se√ß√£o 4, os conceitos da ferramenta Amazon Bedrock s√£o mais aprofundados, assim como a sua utiliza√ß√£o.

Amazon Bedrock √© um servi√ßo totalmente gerenciado pela AWS e servless, ou seja, voc√™ √© cobrado apenas pelo que usa. Existem v√°rios modelos fundamentais que est√£o dispon√≠veis no Bedrock, mas nessa sprint, trabalhei apenas com o `Llama` da Meta, `Claude 3 Haiku` da Anthropic e o `Titan Image Generator G1` da Amazon.

√â poss√≠vel fazer uma customiza√ß√£o de modelos atrav√©s do **fine-tuning**, onde voc√™ pode ajuste um modelo de IA para tarefas espec√≠ficas usando um conjunto de dados rotulado.

A arquitetura do AWS Bedrock segue o seguinte fluxo: Solicita√ß√£o do cliente -> Processamento no AWS Bedrock -> Chamada ao provedor de modelos -> Acesso ao modelo base(fundamental).

Tr√™s principais componentes:
- **Runtime Inference**: Determina para qual endpoint o pedido ser√° enviado.
- **Base Model**: Modelos pr√©-treinados dispon√≠veis para os clientes.
- **Bedrock Service**: Camada gerenciada da AWS que conecta os clientes aos modelos de IA.

Os par√¢metros de infer√™ncia influenciam diretamente na forma como os modelos de IA Generativa ir√£o gerar as respostas. Abaixo, os principais par√¢metros para cada categoria s√£o descritos:

**1. Randomness and Diversity**
- **Temperature**: Controla a aleatoriedade na escolha das palavras. Valores mais altos resultam em respostas mais criativas e imprevis√≠veis.

- **Top K**: Define um limite para a quantidade de palavras candidatas para cada pr√≥xima palavra gerada.

- **Top P**: Usa um crit√©rio de probabilidade cumulativa para limitar as escolhas de palavras.

**2. Length**
- **Response Length**: Determina o n√∫mero m√°ximo de tokens (palavras ou partes de palavras) gerados.

- **Length Penalty**: Penaliza respostas muito curtas ou muito longas para equilibrar a sa√≠da.

- **Stop Sequence**: Define uma sequ√™ncia espec√≠fica que faz o modelo parar de gerar texto quando encontrada.

**3. Repetition**
- **Repetition Penalty**: Reduz a probabilidade de repetir palavras ou frases.

### Section 5: Enterprise Use Case 1: Image Generation 
Na se√ß√£o 5 estudamos um caso de uso de IA Generativa com o objetivo de **gerar um design de um cartaz de um fime**.

O fluxo utilizado para trabalhar com a IA Generativa √© descrito abaixo:

O Usu√°rio vai utilizar uma API Rest para **realizar um prompt** para um `API Gateway`, que vai gerar um evento para uma fun√ß√£o do `AWS Lambda` que vai encaminhar o **prompt + os par√¢metros de infer√™ncia** para o `AWS Bedrock`. O Bedrock vai interagir com a IA Generativa que vai **gerar a imagem**, e ele tamb√©m vai armazen√°-la em um `bucket S3`.

O passo-a-passo para implementa√ß√£o da arquitetura √© o seguinte:

1. Cria√ß√£o do bucket
2. Cria√ß√£o da fun√ß√£o AWS Lambda
3. Cria√ß√£o de uma API Rest usando o AWS API Gateway
4. Testar utilizando alguma ferramenta de requisi√ß√£o

Ap√≥s criar o bucket s3, criei uma fun√ß√£o AWS Lambda com o objetivo de com um prompt de gera√ß√£o de imagem, realizar uma requisi√ß√£o para o modelo `Titan Image Generator G1`, retornar uma imagem e armazenar no bucket s3 criado.

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/promptTest.png)

Acima, o prompt fornecido por Test que eu estava rodando era **"image of two cats"**.

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/request.png)

As configura√ß√µes da requisi√ß√£o s√£o as acima, onde com a documenta√ß√£o referente ao modelo utilizado, √© poss√≠vel saber o que colocar no **corpo da requisi√ß√£o** e ajustar os **par√¢metros de infer√™ncia** como n√∫mero de imagens, tamanho, qualidade, entre outros.

Ap√≥s mais alguns processos como decodificar a imagem gerado em base64, uma integra√ß√£o com o bucket s3 foi feita, ela foi armazenada nele.

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/armazenando_bucket.png)

A imagem gerada:

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/image_of_2_cats.png)

Nesta se√ß√£o tamb√©m foi criado uma API no servi√ßo `AWS API Gateway`, onde √© poss√≠vel realizar requisi√ß√µes GET atrav√©s do **Invoke URL**, passando o prompt como par√¢metro. Dentro do servi√ßo API Gateway, √© poss√≠vel realizar um teste e ver a response. 

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/request_api.png)

Coloquei o prompt "a sunny day in a beautiful landscape" e obtive a seguinte imagem:

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/beautiful_landscape.png)

### Section 6: Enterprise Use Case 2: Text Summarization
Na se√ß√£o 6, o caso de uso trabalhado, √© a utiliza√ß√£o de **sumariza√ß√£o de texto** com AWS Bedrock para resolu√ß√£o de problemas mais rapidamente. Em um cen√°rio real, esse caso de uso aumentaria a produtividade de t√©cnicos em uma ind√∫stria de manufatura.

Em caso de mal funcionamento ou problemas em algum equipamento em um lugar remoto, t√©cnicos ser√£o acionados para visitar o local. Ap√≥s realizar a vistoria, ele iria **reportar o incidente**. As evid√™ncias ser√£o enviadas para uma aplica√ß√£o feita para receber esse reporte, podendo ser textos ou imagens. Essa aplica√ß√£o ir√° encaminhar o incidente para um modelo base no AWS Bedrock e retornar um **reporte sumarizado e organizado**.

O primeiro passo √© construir uma comunica√ß√£o com o AWS Bedrock. O modelo invocado para a realiza√ß√£o da tarefa foi o `Claude 3 Haiku`. 

![Evidencia](./evidencias/curso_amazon_bedrock/sec6/codigo_invocando_claude.png)

Acima √© poss√≠vel observar que um prompt √© passado no campo messages. Esse prompt foi definido no evento de teste como uma pergunta **"What are you?"**, para fins de teste. A seguinte resposta foi retornada pelo Claude.

![Evidencia](./evidencias/curso_amazon_bedrock/sec6/response_claude.png)

Outro passo muito importante foi a cria√ß√£o da API atrav√©s do API Gateway. Ap√≥s criar o m√©todo POST e realizar um deploy, a API ficou dispon√≠vel para utiliza√ß√£o. Realizei um teste na ferramenta Insomnia atrav√©s do Invoke URL, passando no body, um prompt que cont√©m um **exemplo de reporte que pode ter sido realizado por um t√©cnico** e pedi para sumariz√°-lo em 2 linhas.

A Request:
![Evidencia](./evidencias/curso_amazon_bedrock/sec6/request_insomnia.png)

A Response:
![Evidencia](./evidencias/curso_amazon_bedrock/sec6/response_insomnia.png)


### Section 7: Use Case 3: Building a Chatbot
Nesta se√ß√£o contru√≠mos um **Chatbot** utilizando ferramentas como `Stramlit` + `Langchain` + `Bedrock`.

Para fins de contexto, **Streamlit** √© uma biblioteca em Python que facilita a cria√ß√£o de **interfaces web interativas**. **Langchain** tamb√©m √© uma biblioteca, e facilita a constru√ß√£o de **aplica√ß√µes que s√£o baseads em LLMs**.

O fluxo da arquitetura pode ser representado da seguinte maneira:

- O usu√°rio **interage com o chatbot** atrav√©s da interface do Streamlit
- O chatbot usa a **Langchain Memory** para recuperar mensagens anteriores e manter o **contexto da conversa**
- O Langchain combina a **pergunta atual** com o **hist√≥rico de conversa** para formar um prompt mais completo
- O prompt √© enviado para um modelo de IA na Amazon Bedrock, que **processa a pergunta e gera uma resposta**
- A resposta gerada pelo modelo da Amazon Bedrock √© **processada e formatada** para garantir que esteja correta.
- A **resposta √© exibida** na interface do Streamlit, completando o ciclo de intera√ß√£o.

Atrav√©s das credenciais de acesso da AWS no ambiente de trabalho, foi poss√≠vel utilizar modelos fundamentais como o Claude 3 Haiku para construir o chatbot.

![Evidencia](./evidencias/curso_amazon_bedrock/sec7/claude3_haiku.png)

Passei o prompt "Hi, what is your name?" como input e rodei o c√≥digo e obtive a seguinte resposta:

![Evidencia](./evidencias/curso_amazon_bedrock/sec7/response_claude3.png)

O modelo j√° estava provendo respostas, portanto, foi preciso realizar mais algumas configura√ß√µes como o buffer de conversas para quest√µes como a mem√≥ria e hist√≥rico sejam exploradas.

![Evidencia](./evidencias/curso_amazon_bedrock/sec7/erro_frontend.png)

Infelizmente n√£o consegui explorar muito a utilzia√ß√£o da interface por conta de um erro que n√£o consegui resolu√ß√£o.

### Section 8: Overview of Vectors & Embeddings
A se√ß√£o 8 foi muito interessante para relembrar conceitos fundamentais de machine learning e processamento de linguagem natural(NLP) como os **vetores** e **embeddings**.

Os embeddings s√£o representa√ß√µes vetoriais densas de dados textuais. Eles transformam texto em **vetores num√©ricos** que capturam o significado sem√¢ntico das palavras, frases ou documentos. 

Nesta se√ß√£o desenvolvemos um c√≥digo onde utilizamos o modelo fundamental `Amazon Titan Embedding Text v2` para gerar um **embedding como resposta para um prompt passado**. Nesse contexto, eu passei o input: "Hi! My name is Matheus. How are you?". Esse texto foi enviado ao modelo, que processa o texto e gera um emebdding.

Atrav√©s do CloudWatch, vemos o Log gerado com as informa√ß√µes impressas.

![Evidencia](./evidencias/curso_amazon_bedrock/sec8/log_cloud_watch_embedding.png)

Acima √© poss√≠vel ver o prompt passado em conjunto com seu n√∫mero de tokens gerados, o total de embeddings gerados e o vetor denso que representa o texto de resposta.   


### Section 9: Use Case 4: Building HR Q&A
Na se√ß√£o 9 n√≥s trabalhamos com o HR Q&A com RAG, que √© um sistema de **perguntas e respostas(Q&A)** voltado para **recursos humanos(HR)**, utilizando a t√©cnica de **gera√ß√£o aumentada por recupera√ß√£o(RAG)** para melhorar a precis√£o das respostas fornecidas por um modelo de intelig√™ncia artificial.

**Retrieval-Augmented Generation(RAG)** √© um conceito novo que √© importante de ser entendido. RAG √© uma abordagem de intelig√™ncia artificial generativa que busca melhorar a precis√£o das respostas. Isso √© algo importante, pois modelos de IA generativa podem **inventar respostas**, conhecido como alucina√ß√µes, ou ger√°-las com base a**penas nos dados que aprendeu durante o treinamento**. 

Com o RAG, um sistema busca informa√ß√µes relevantes em um **banco de dados** ou **corpus de documentos** (ex.: PDFs, sites, bases de conhecimento).  O modelo de linguagem recebe tanto a pergunta do usu√°rio quanto o contexto recuperado.

Com o contexto acima, o sistema de perguntas e respostas voltado para recursos humanos foi criado.

O c√≥digo implementa uma interface funcional para:

- Carregar e processar documentos PDF.
- Dividir o texto em chunks menores.
- Criar embeddings para os chunks de texto.
- Armazenar os embeddings em um banco de dados vetorial.
- Configurar e usar um modelo de linguagem para responder a perguntas com base nos dados processados.

![Evidencia](./evidencias/curso_amazon_bedrock/sec9/hr_QA_interface.png)

Acima, tem-se um exemplo de uso, onde o prompt passado foi **"how many time leave for maternity?"**.

# üë®üèº‚Äçüéì Certificados

## üß† Curso: Credit Risk Modeling in Python


## üß† Curso: Amazon Bedrock, Amazon Q & AWS Generative AI

