
<h1 align="center">
    <strong>SPRINT 07</strong>
</h1>

# üîó V√≠deo - [Desafio Sprint 07](https://compasso-my.sharepoint.com/:v:/r/personal/matheus_azevedo_pb_compasso_com_br/Documents/Sprint7_Video_Desafio_MatheusAzevedo.mp4?csf=1&web=1&e=2vi8vx)


# üìù Exerc√≠cios

## üß† Curso: Credit Risk Modeling in Python

Clique [aqui](./exercicios/curso_credit_risk/) para visualizar os notebooks gerados do curso Credit Risk

## üß† Curso: Amazon Bedrock, Amazon Q & AWS Generative AI

Clique [aqui](./exercicios/curso_amazon_bedrock/) para visualizar os c√≥digos gerados do curso Amazon Bedrock

# üîé Evid√™ncias

## üß† Curso: Credit Risk Modeling in Python

### Section 1: Introduction

### Section 3: Dataset description
O dataset em que trabalhamos nesse curso cont√©m  mais de 800.000 empr√©stimos emitidos entre 2007 e 2015 pela Lending Club. O dataset inclui a situa√ß√£o atual do empr√©stimo (atual, atrasado, totalmente pago, etc.) e as informa√ß√µes de pagamento mais recentes. As features incluem pontua√ß√£o de cr√©dito, n√∫mero de consultas financeiras, endere√ßo incluindo c√≥digos postais e estado, e cobran√ßas, entre outros. 

**Link para o dataset no [Kaggle](https://www.kaggle.com/datasets/adarshsng/lending-club-loan-data-csv)**

### Section 4: General preprocessing
Na se√ß√£o 4, um processamento geral do dataset foi feito. Nesse pr√©-processamento, foram tratadas **vari√°veis dicretas** e **cont√≠nuas**.

- **Vari√°veis cont√≠nuas:** Podem assumir um n√∫mero **infinito** de valores dentro de um intervalo espec√≠fico<br>

    **Exemplos:** renda anual (`annual_inc`), d√≠vida sobre renda (`dti`), tempo desde o √∫ltimo atraso (`mths_since_last_delinq`).

- **Vari√°veis discretas:** Assumem um n√∫mero **finito** de valores.

    **Exemplos:**  n√∫mero de inadimpl√™ncias passadas (`delinq_2yrs`), quantidade de contas em aberto (`open_acc`)


Outro passo muito importante para vari√°veis cont√≠nuas e discretas foi a cria√ß√£o de **vari√°veis dummy**. Como j√° √© sabido, vari√°veis categ√≥ricas precisam ser transformadas para que um modelo possa utiliz√°-la. Portanto, realiza-se o one-hot-encoding.

![Evidencia](./evidencias/curso_credit_risk/sec4/dummies.png)

Al√©m disso, foi realizado um um check por valores faltantes, que foram tratados posteriormente na etapa de prepara√ß√£o de dados.

![Evidencia](./evidencias/curso_credit_risk/sec4/missing_values.png)


### Section 5: PD model: Data Preparation
Nesta se√ß√£o trabalhamos diretamente na modelagem de risco de cr√©dito, que visa prever a **probabilidade de inadimpl√™ncia (default)** de um cliente, ou seja, a probabilidade de um devedor n√£o pagar as suas d√≠vidas at√© √† data de vencimento.

Portanto, trabalhamos com o PD Model(Probability of Default Model), um modelo que √© treinado para estimar essa probabilidade.

A vari√°vel-alvo do modelo √© **"good/bad loan"**, indicando se um empr√©stimo foi pago normalmente ou se houve inadimpl√™ncia. O dataset √© preparado de forma que os padr√µes que diferenciam bons e maus pagadores possam ser identificados pelo modelo.

Exemplo de prepara√ß√£o dos dados
![Evidencia](./evidencias/curso_credit_risk/sec5/data_preparation.png)

Existem 3 conceitos que foram muito utilizados nessa se√ß√£o que s√£o importantes de serem ressaltados, eles s√£o: `Weight of Evidence`, `Fine Classing` e `Coarse Classing`.

- **Weight of Evidence(WoE):** √â uma m√©trica que mede a separa√ß√£o entre duas classes (por exemplo, inadimplentes e n√£o inadimplentes) dentro de um conjunto de dados. Ela √© c√°lculada da seguinte forma:

    ![Evidencia](./evidencias/curso_credit_risk/sec5/woe_formula.png)

    Onde `%good` √© a porcentagem de bons pagadores, ou seja, aqueles que pagaram o empr√©stimo corretamente. J√° `%bad`s√£o os pagadores que ficaram inadimplentes

    No exemplo abaixo, √© poss√≠vel observar a coluna WoE no dataframe:

    ![Evidencia](./evidencias/curso_credit_risk/sec5/woe_in_df.png)

    Se o WoE for **positivo**, significa que o grupo **tem mais bons pagadores** do que a m√©dia da popula√ß√£o.<br>
    Se o WoE for **negativo**, significa que h√° **mais maus pagadores** do que a m√©dia.

- **Fine Classing e Coarse Classing:** Esses m√©todos s√£o formas de dividir vari√°veis em **grupos discretos**.

    Com o **fine classing**, cria-se muitos grupos pequenos, ou seja, as vari√°veis cont√≠nuas s√£o divididas em muitas **faixas(bins)**.

    Com o **coarse classing**, muitos grupos pequenos s√£o reduzidos para **grupos maiores**.


Previamente foi introduzido os conceitos de vari√°veis categ√≥ricas e num√©ricas, al√©m do conceito de Weight of Evidence. Nesta se√ß√£o, trabalhamos com fun√ß√µes que facilitaram muito o pr√©-processamento de vari√°veis discretas e cont√≠nuas, sendo a `woe_discrete` e `woe_ordereded_continuous`, respectivamente.

- Exemplo de uso da woe_discrete:
![Evidencia](./evidencias/curso_credit_risk/sec5/woe_discrete.png)

- Exemplo de uso da woe_ordered_continuous:
![Evidencia](./evidencias/curso_credit_risk/sec5/woe_ordered_continuous.png)

As duas fun√ß√µes seguem o mesmo princ√≠pio:
1. Agrupar os dados.
2. Calcular propor√ß√µes de bons e maus pagadores.
3. Calcular o WoE.
4. Calcular o IV.

A principal diferen√ßa √© que `woe_ordered_continuous `√© aplicada a vari√°veis cont√≠nuas que foram previamente divididas em bins.

Outra fun√ß√£o muito importante para essa se√ß√£o, √© a `plot_woe`, que com uma vari√°vel passada por par√¢metro, imprime um gr√°fico para visualizar a rela√ß√£o do **WoE de uma vari√°vel categ√≥rica ou de bins de uma vari√°vel cont√≠nua**.

No exemplo abaixo, plotei um gr√°fico para visualizar o WoE da vari√°vel cont√≠nua emp_lenght, que representa o tempo de emprego de um funcion√°rio.

![Evidencia](./evidencias/curso_credit_risk/sec5/woe_emp_length_int.png)

O eixo X representa o **tempo de emprego (emp_length_int)**, variando de 0 anos (menos de 1 ano de experi√™ncia) at√© 10 anos ou mais.<br>
O eixo Y representa o **WoE**, que indica a propor√ß√£o relativa de bons pagadores dentro de cada grupo.

√â poss√≠vel fazer diversas infer√™ncias, mas algumas f√°ceis de observar s√£o: Para 0 anos, o WoE √© negativo **(-0.1 aproximadamente)**, indicando que essa categoria tem uma **propor√ß√£o maior de maus pagadores** comparada ao total da amostra.<br>  
Para 10 anos ou mais, o WoE atinge seu maior valor (~0.1), indicando que pessoas com mais tempo de emprego t√™m **menor risco de inadimpl√™ncia**.

### Section 6: PD model estimation
Na se√ß√£o 6, utilizamos os datasets que foram exportados da se√ß√£o 5 para estimar o treinamento do PD Model.

O uso da regress√£o log√≠stica faz sentido pois ela √© **adequada para modelar probabilidades**. O PD model basicamente estima a probabilidade de um evento bin√°rio, ou seja, *default (1)* ou *n√£o-default(0)*.

Tamb√©m foi feita uma **feature selection** com o aux√≠lio dos **p-values** para avalia√ß√£o da signific√¢ncia estat√≠stica das vari√°veis preditoras, essencial para manter vari√°veis relevantes e descartas aquelas que n√£o tem impacto na previs√£o de default.

O que eram antes 104 vari√°veis, ap√≥s a feature selection ficaram 85.

![Evidencia](./evidencias/curso_credit_risk/sec6/feature_selection.png)

![Evidencia](./evidencias/curso_credit_risk/sec6/summary_table_shape.png)

### Section 7: PD model validation
Na se√ß√£o 7 validamos o PD model utilizando m√©tricas como AUC, ROC e Gini para avalia√ß√£o do desenp√©nho do modelo.

√â importante que esses conceitos sejam contextualizados:

- **AUC (Area under the curve):**
    A AUC √© uma m√©trica que mede a capacidade do modelo de distinguir entre classes (neste caso, **empr√©stimos bons e ruins**).

    Um valor de AUC pr√≥ximo a 1 indica que o modelo tem uma alta capacidade de discrimina√ß√£o, enquanto um valor pr√≥ximo a 0.5 sugere que o modelo n√£o √© melhor do que uma escolha aleat√≥ria.

    ![Evidencia](./evidencias/curso_credit_risk/sec7/roc.png)

- **ROC (Receiver Operating Characteristic):**
    A curva ROC √© um gr√°fico que mostra a taxa de **verdadeiros positivos (TPR)** em fun√ß√£o da taxa de **falsos positivos (FPR)** para diferentes pontos de corte.

    A curva ROC ajuda a visualizar o desempenho do modelo em diferentes limiares de classifica√ß√£o

- **Gini:**
    O coeficiente de Gini √© uma medida de desigualdade que pode ser derivada da AUC. Ele √© calculado como Gini = 2 * AUC - 1.

    Um valor de Gini pr√≥ximo a 1 indica um modelo com alta capacidade de discrimina√ß√£o, enquanto um valor pr√≥ximo a 0 indica um modelo com baixa capacidade de discrimina√ß√£o.

- **Teste de Kolmogorov-Smirnov(KS)**
    O teste de Kolmogorov-Smirnov √© um teste n√£o param√©trico usado para comparar **duas distribui√ß√µes**(ou uma distribui√ß√£o observada com uma te√≥rica). Ele mede a maior diferen√ßa absoluta entre as fun√ß√µes de distribui√ß√£o acumulada (CDFs) das duas distribui√ß√µes.

    ![Evidencia](./evidencias/curso_credit_risk/sec7/kolmogorov.png)

### Section 8: Applying the PD model for decision making
Na se√ß√£o 8, o principal feito foi a cria√ß√£o do **scorecard**, uma tabela de refer√™ncia para categorias de vari√°veis 

### Section 9: PD model monitoring
Nesta se√ß√£o √© monitorado o desempenho do modelo PD ao longo do tempo. Os principais pontos incluem:

**An√°lise de Performance:**
    Compara√ß√£o entre as previs√µes de PD e os resultados reais.
    Verifica√ß√£o de desvios no modelo ao longo do tempo.
    Uso de m√©tricas como Kolmogorov-Smirnov (KS) e √Årea Sob a Curva (AUC-ROC) para medir a discrimina√ß√£o do modelo.

**Gr√°ficos e Tabelas:**
    Plots para visualizar a distribui√ß√£o das probabilidades previstas versus observadas.
    Monitoramento de drift do modelo, identificando poss√≠veis deteriora√ß√µes na precis√£o.

**Recalibra√ß√£o do Modelo:**
    Ajuste de coeficientes para manter a acur√°cia do modelo.
    Atualiza√ß√£o de vari√°veis preditivas para lidar com mudan√ßas no comportamento dos clientes.


### Section 11: LGD model & Section 12: EAD model

Aqui s√£o constru√≠dos e avaliados os modelos de **Loss Given Default (LGD)** e **Exposure at Default (EAD)**, componentes cr√≠ticos para estimar perdas esperadas.

- **Loss Given Default (LGD):**
    O modelo √© dividido em duas etapas:<br>
    Recupera√ß√£o Inicial (recovery_rate_st_1): Uma regress√£o estima a recupera√ß√£o inicial ap√≥s o default.

    Recupera√ß√£o Ajustada (recovery_rate_st_2): Um segundo modelo refina a previs√£o da taxa de recupera√ß√£o.

- **C√°lculo Final do LGD:**
    LGD = 1 - recovery_rate (taxa de recupera√ß√£o).
    Valores de LGD s√£o ajustados entre 0 e 1 para evitar previs√µes inv√°lidas.

- **Exposure at Default (EAD):**
    Modelo de Credit Conversion Factor (CCF) estima a fra√ß√£o do limite de cr√©dito utilizado no momento do default.
    
    O EAD final √© obtido como:
    **EAD=CCF√óValor Financiado**
    Assim como no LGD, valores de EAD s√£o restringidos entre 0 e 1.


### Section 13: Calculating expected loss
Esta se√ß√£o combina** PD, LGD e EAD** para calcular a **Perda Esperada (EL)**, fundamental para precifica√ß√£o de risco e provis√µes banc√°rias.

- **Prepara√ß√£o dos Dados:**
    Substitui√ß√£o de valores nulos em vari√°veis cr√≠ticas.
    Jun√ß√£o das previs√µes de PD, LGD e EAD no conjunto de dados.

- **F√≥rmula da Perda Esperada:**
    **EL=PD√óLGD√óEAD**

    O c√°lculo √© feito para cada contrato de cr√©dito, gerando uma estimativa de perda ajustada ao risco.

- **Valida√ß√£o e Estat√≠sticas:**
    Descri√ß√£o estat√≠stica dos valores calculados de EL.
    An√°lises para verificar a coer√™ncia dos resultados.


## üß† Curso: Amazon Bedrock, Amazon Q & AWS Generative AI

### Section 2: Basics of AI, ML & Neural Networks
A se√ß√£o 2 foi interessante de ser realizada para a recorda√ß√£o de importantes conceitos que vemos durante a trilha relacionados Intelig√™ncia Artificial(AI), Machine Learning(ML), Deep Learning(DL) e Generative AI.

- **Aprendizado supervisionado**: modelos s√£o treinados utilizando **datasets rotulados**. O objetivo √© que o modelo aprenda a mapear as entradas para as sa√≠das corretas e consiga fazer previs√µes para novos dados. Esse tipo de aprendizado √© utilizando para resolver problemas de **classifica√ß√£o** e **regress√£o**.

- **Aprendizado n√£o supervisionado**: o algoritmo √© treinado utilizando **datasets n√£o rotulados**. Baseado no conjunto de dados, o modelo consegue encontrar padr√µes escondidos e insights baseados nas similaridades dos dados. Esse tipo de aprendizado √© muito utilizado em problemas de **clusteriza√ß√£o** e **redu√ß√£o de dimensionalidade**.

- **Deep Learning**: sub√°rea de Machine Learning que utiliza redes neurais profundas para **aprender representa√ß√µes complexas dos dados**. O treinamento dessas redes exige grandes volumes de dados e alto poder computacional. Muito utilizado para **reconhecimento de imagens** e **processamento de linguagem natural**.

- **IA Generativa**: sub√°rea de Deep Learning que foca em criar modelos capazes de **gerar conte√∫do** a partir de padr√µes aprendidos. Por exemplo, pode-se ter IA's generativas baseadas em texto, imagens, v√≠deos, a√∫dios, c√≥digo, entre outros. ChatGPT, DeepSeek, MidJourney s√£o exemplos de IA's generativas.

### Section 3: Generative AI & Foundation Models Concepts
Nesta se√ß√£o 3, a gente vai um pouco mais fundo no conceito de IA Generativa.

Utilizando o **Chat/Text playground** do `Claude 3 Haiku`, eu perguntei "O que √© uma IA Generativa?", e ela me retornou a seguinte resposta:

![Evidencia](./evidencias/curso_amazon_bedrock/sec3/ia_generativa.png)

Uma IA Generativa funciona atrav√©s de um `modelo fundamental`, que √© o modelo treinado com um grande conjunto de dados para capturar padr√µes gerais. 

A IA √© utilizada atrav√©s de um `prompt`, que significa a entrada do usu√°rio, podendo ser um texto, uma imagem, v√≠deo ou a√∫dio, contendo uma instru√ß√£o do usu√°rio para a IA.

O processamento do prompt fornecido pelo usu√°rio √© realizado pela IA para analisar o prompt e prever uma melhor resposta com base no que aprendeu no treinamento. Esse proceso √© chamado de `infer√™ncia`, e a resposta gerada, √© chamada de `completion`.

Ap√≥s receber um prompt, a IA realiza o proceso de `tokeniza√ß√£o`, que transforma o prompt em tokens num√©ricos, al√©m disso, ela deve levar em conta a janela de contexto(`context window`), que define quantos tokens o modelo pode levar em considera√ß√£o para dar uma resposta. O `detokenizer` reconverte os tokens para palavras, para gerar o completion.

√â importante compreender 3 conceitos de modelos fundamentais.

- **Tokens**: um token geralmente corresponde a 4 caracteres de texto.
- **Parameters**- n√∫meo de conex√µes e pesos entre n√≥s em uma rede neural.
- **Temperature** - par√¢metro que controla a criatividade e diversidade do modelo.

Exemplo de resposta do modelo `Llama` da Meta para o prompt *"Qual √© o melhor jogador de todos os tempos?"*, com par√¢metros como **Temperature** e **Top P** ajustados.

![Evidencia](./evidencias/curso_amazon_bedrock/sec3/chat_llama.png)

Outro caso de uso de IA Generativa, √© a **gera√ß√£o de imagens**, como no exemplo abaixo, onde utilizei o modelo `Titan Image Generator` da Amazon e coloquei um o prompt: *"Um gato fazendo exerc√≠cios na academia"*. A IA me retornou a imagem abaixo:

![Evidencia](./evidencias/curso_amazon_bedrock/sec3/Um%20gato%20fazendo%20exerc√≠cios%20na%20academia.png)

### Section 4: Amazon Bedrock - Deep Dive
Na se√ß√£o 4, os conceitos da ferramenta Amazon Bedrock s√£o mais aprofundados, assim como a sua utiliza√ß√£o.

Amazon Bedrock √© um servi√ßo totalmente gerenciado pela AWS e servless, ou seja, voc√™ √© cobrado apenas pelo que usa. Existem v√°rios modelos fundamentais que est√£o dispon√≠veis no Bedrock, mas nessa sprint, trabalhei apenas com o `Llama` da Meta, `Claude 3 Haiku` da Anthropic e o `Titan Image Generator G1` da Amazon.

√â poss√≠vel fazer uma customiza√ß√£o de modelos atrav√©s do **fine-tuning**, onde voc√™ pode ajuste um modelo de IA para tarefas espec√≠ficas usando um conjunto de dados rotulado.

A arquitetura do AWS Bedrock segue o seguinte fluxo: Solicita√ß√£o do cliente -> Processamento no AWS Bedrock -> Chamada ao provedor de modelos -> Acesso ao modelo base(fundamental).

Tr√™s principais componentes:
- **Runtime Inference**: Determina para qual endpoint o pedido ser√° enviado.
- **Base Model**: Modelos pr√©-treinados dispon√≠veis para os clientes.
- **Bedrock Service**: Camada gerenciada da AWS que conecta os clientes aos modelos de IA.

Os par√¢metros de infer√™ncia influenciam diretamente na forma como os modelos de IA Generativa ir√£o gerar as respostas. Abaixo, os principais par√¢metros para cada categoria s√£o descritos:

**1. Randomness and Diversity**
- **Temperature**: Controla a aleatoriedade na escolha das palavras. Valores mais altos resultam em respostas mais criativas e imprevis√≠veis.

- **Top K**: Define um limite para a quantidade de palavras candidatas para cada pr√≥xima palavra gerada.

- **Top P**: Usa um crit√©rio de probabilidade cumulativa para limitar as escolhas de palavras.

**2. Length**
- **Response Length**: Determina o n√∫mero m√°ximo de tokens (palavras ou partes de palavras) gerados.

- **Length Penalty**: Penaliza respostas muito curtas ou muito longas para equilibrar a sa√≠da.

- **Stop Sequence**: Define uma sequ√™ncia espec√≠fica que faz o modelo parar de gerar texto quando encontrada.

**3. Repetition**
- **Repetition Penalty**: Reduz a probabilidade de repetir palavras ou frases.

### Section 5: Enterprise Use Case 1: Image Generation 
Na se√ß√£o 5 estudamos um caso de uso de IA Generativa com o objetivo de **gerar um design de um cartaz de um fime**.

O fluxo utilizado para trabalhar com a IA Generativa √© descrito abaixo:

O Usu√°rio vai utilizar uma API Rest para **realizar um prompt** para um `API Gateway`, que vai gerar um evento para uma fun√ß√£o do `AWS Lambda` que vai encaminhar o **prompt + os par√¢metros de infer√™ncia** para o `AWS Bedrock`. O Bedrock vai interagir com a IA Generativa que vai **gerar a imagem**, e ele tamb√©m vai armazen√°-la em um `bucket S3`.

O passo-a-passo para implementa√ß√£o da arquitetura √© o seguinte:

1. Cria√ß√£o do bucket
2. Cria√ß√£o da fun√ß√£o AWS Lambda
3. Cria√ß√£o de uma API Rest usando o AWS API Gateway
4. Testar utilizando alguma ferramenta de requisi√ß√£o

Ap√≥s criar o bucket s3, criei uma fun√ß√£o AWS Lambda com o objetivo de com um prompt de gera√ß√£o de imagem, realizar uma requisi√ß√£o para o modelo `Titan Image Generator G1`, retornar uma imagem e armazenar no bucket s3 criado.

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/promptTest.png)

Acima, o prompt fornecido por Test que eu estava rodando era **"image of two cats"**.

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/request.png)

As configura√ß√µes da requisi√ß√£o s√£o as acima, onde com a documenta√ß√£o referente ao modelo utilizado, √© poss√≠vel saber o que colocar no **corpo da requisi√ß√£o** e ajustar os **par√¢metros de infer√™ncia** como n√∫mero de imagens, tamanho, qualidade, entre outros.

Ap√≥s mais alguns processos como decodificar a imagem gerado em base64, uma integra√ß√£o com o bucket s3 foi feita, ela foi armazenada nele.

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/armazenando_bucket.png)

A imagem gerada:

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/image_of_2_cats.png)

Nesta se√ß√£o tamb√©m foi criado uma API no servi√ßo `AWS API Gateway`, onde √© poss√≠vel realizar requisi√ß√µes GET atrav√©s do **Invoke URL**, passando o prompt como par√¢metro. Dentro do servi√ßo API Gateway, √© poss√≠vel realizar um teste e ver a response. 

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/request_api.png)

Coloquei o prompt "a sunny day in a beautiful landscape" e obtive a seguinte imagem:

![Evidencia](./evidencias/curso_amazon_bedrock/sec5/beautiful_landscape.png)

### Section 6: Enterprise Use Case 2: Text Summarization
Na se√ß√£o 6, o caso de uso trabalhado, √© a utiliza√ß√£o de **sumariza√ß√£o de texto** com AWS Bedrock para resolu√ß√£o de problemas mais rapidamente. Em um cen√°rio real, esse caso de uso aumentaria a produtividade de t√©cnicos em uma ind√∫stria de manufatura.

Em caso de mal funcionamento ou problemas em algum equipamento em um lugar remoto, t√©cnicos ser√£o acionados para visitar o local. Ap√≥s realizar a vistoria, ele iria **reportar o incidente**. As evid√™ncias ser√£o enviadas para uma aplica√ß√£o feita para receber esse reporte, podendo ser textos ou imagens. Essa aplica√ß√£o ir√° encaminhar o incidente para um modelo base no AWS Bedrock e retornar um **reporte sumarizado e organizado**.

O primeiro passo √© construir uma comunica√ß√£o com o AWS Bedrock. O modelo invocado para a realiza√ß√£o da tarefa foi o `Claude 3 Haiku`. 

![Evidencia](./evidencias/curso_amazon_bedrock/sec6/codigo_invocando_claude.png)

Acima √© poss√≠vel observar que um prompt √© passado no campo messages. Esse prompt foi definido no evento de teste como uma pergunta **"What are you?"**, para fins de teste. A seguinte resposta foi retornada pelo Claude.

![Evidencia](./evidencias/curso_amazon_bedrock/sec6/response_claude.png)

Outro passo muito importante foi a cria√ß√£o da API atrav√©s do API Gateway. Ap√≥s criar o m√©todo POST e realizar um deploy, a API ficou dispon√≠vel para utiliza√ß√£o. Realizei um teste na ferramenta Insomnia atrav√©s do Invoke URL, passando no body, um prompt que cont√©m um **exemplo de reporte que pode ter sido realizado por um t√©cnico** e pedi para sumariz√°-lo em 2 linhas.

A Request:
![Evidencia](./evidencias/curso_amazon_bedrock/sec6/request_insomnia.png)

A Response:
![Evidencia](./evidencias/curso_amazon_bedrock/sec6/response_insomnia.png)


### Section 7: Use Case 3: Building a Chatbot
Nesta se√ß√£o contru√≠mos um **Chatbot** utilizando ferramentas como `Stramlit` + `Langchain` + `Bedrock`.

Para fins de contexto, **Streamlit** √© uma biblioteca em Python que facilita a cria√ß√£o de **interfaces web interativas**. **Langchain** tamb√©m √© uma biblioteca, e facilita a constru√ß√£o de **aplica√ß√µes que s√£o baseads em LLMs**.

O fluxo da arquitetura pode ser representado da seguinte maneira:

- O usu√°rio **interage com o chatbot** atrav√©s da interface do Streamlit
- O chatbot usa a **Langchain Memory** para recuperar mensagens anteriores e manter o **contexto da conversa**
- O Langchain combina a **pergunta atual** com o **hist√≥rico de conversa** para formar um prompt mais completo
- O prompt √© enviado para um modelo de IA na Amazon Bedrock, que **processa a pergunta e gera uma resposta**
- A resposta gerada pelo modelo da Amazon Bedrock √© **processada e formatada** para garantir que esteja correta.
- A **resposta √© exibida** na interface do Streamlit, completando o ciclo de intera√ß√£o.

Atrav√©s das credenciais de acesso da AWS no ambiente de trabalho, foi poss√≠vel utilizar modelos fundamentais como o Claude 3 Haiku para construir o chatbot.

![Evidencia](./evidencias/curso_amazon_bedrock/sec7/claude3_haiku.png)

Passei o prompt "Hi, what is your name?" como input e rodei o c√≥digo e obtive a seguinte resposta:

![Evidencia](./evidencias/curso_amazon_bedrock/sec7/response_claude3.png)

O modelo j√° estava provendo respostas, portanto, foi preciso realizar mais algumas configura√ß√µes como o buffer de conversas para quest√µes como a mem√≥ria e hist√≥rico sejam exploradas.

![Evidencia](./evidencias/curso_amazon_bedrock/sec7/erro_frontend.png)

Infelizmente n√£o consegui explorar muito a utilzia√ß√£o da interface por conta de um erro que n√£o consegui resolu√ß√£o.

### Section 8: Overview of Vectors & Embeddings
A se√ß√£o 8 foi muito interessante para relembrar conceitos fundamentais de machine learning e processamento de linguagem natural(NLP) como os **vetores** e **embeddings**.

Os embeddings s√£o representa√ß√µes vetoriais densas de dados textuais. Eles transformam texto em **vetores num√©ricos** que capturam o significado sem√¢ntico das palavras, frases ou documentos. 

Nesta se√ß√£o desenvolvemos um c√≥digo onde utilizamos o modelo fundamental `Amazon Titan Embedding Text v2` para gerar um **embedding como resposta para um prompt passado**. Nesse contexto, eu passei o input: "Hi! My name is Matheus. How are you?". Esse texto foi enviado ao modelo, que processa o texto e gera um emebdding.

Atrav√©s do CloudWatch, vemos o Log gerado com as informa√ß√µes impressas.

![Evidencia](./evidencias/curso_amazon_bedrock/sec8/log_cloud_watch_embedding.png)

Acima √© poss√≠vel ver o prompt passado em conjunto com seu n√∫mero de tokens gerados, o total de embeddings gerados e o vetor denso que representa o texto de resposta.   


### Section 9: Use Case 4: Building HR Q&A
Na se√ß√£o 9 n√≥s trabalhamos com o HR Q&A com RAG, que √© um sistema de **perguntas e respostas(Q&A)** voltado para **recursos humanos(HR)**, utilizando a t√©cnica de **gera√ß√£o aumentada por recupera√ß√£o(RAG)** para melhorar a precis√£o das respostas fornecidas por um modelo de intelig√™ncia artificial.

**Retrieval-Augmented Generation(RAG)** √© um conceito novo que √© importante de ser entendido. RAG √© uma abordagem de intelig√™ncia artificial generativa que busca melhorar a precis√£o das respostas. Isso √© algo importante, pois modelos de IA generativa podem **inventar respostas**, conhecido como alucina√ß√µes, ou ger√°-las com base **apenas nos dados que aprendeu durante o treinamento**. 

Com o RAG, um sistema busca informa√ß√µes relevantes em um **banco de dados** ou **corpus de documentos** (ex.: PDFs, sites, bases de conhecimento).  O modelo de linguagem recebe tanto a pergunta do usu√°rio quanto o contexto recuperado.

Com o contexto acima, o sistema de perguntas e respostas voltado para recursos humanos foi criado.

O c√≥digo implementa uma interface funcional para:

- Carregar e processar documentos PDF.
- Dividir o texto em chunks menores.
- Criar embeddings para os chunks de texto.
- Armazenar os embeddings em um banco de dados vetorial.
- Configurar e usar um modelo de linguagem para responder a perguntas com base nos dados processados.

![Evidencia](./evidencias/curso_amazon_bedrock/sec9/hr_QA_interface.png)

Acima, tem-se um exemplo de uso, onde o prompt passado foi **"how many time leave for maternity?"**.

# üë®üèº‚Äçüéì Certificados

## üß† Curso: Credit Risk Modeling in Python

![Certificado](./certificados/curso_credit_risk/certificado_credit_risk.png)

## üß† Curso: Amazon Bedrock, Amazon Q & AWS Generative AI

![Certificado](./certificados/curso_amazon_bedrock/certificado_amazon_bedrock.png)