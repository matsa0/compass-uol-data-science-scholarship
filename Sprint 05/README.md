<h1 align="center">
    <strong>SPRINT 05</strong>
</h1>

# üîó V√≠deo - [Desafio Sprint 05](https://compasso-my.sharepoint.com/:v:/r/personal/matheus_azevedo_pb_compasso_com_br/Documents/Sprint5_Video_Desafio_MatheusAzevedo.mp4?csf=1&web=1&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=NJi4DL)

# üìå Projeto 2 

[Clique aqui para visualizar o c√≥digo do projeto](project2.ipynb)

## üìú Introdu√ß√£o

O objetivo do desafio proposto √© atrav√©s do dataset *Used Cars Dataset*, criar um modelo de **Machine Learning** respons√°vel por **prever o pre√ßo de carros**.

Desenvolver esse projeto foi uma excelente forma de exercer na pr√°tica, com um **dataset real**, os aprendizados obtidos em todas as sprints anteriores. Principalmente, trabalhar conceitos **essenciais em um projeto de machine learning** como a an√°lise explorat√≥ria, pr√©-processamento dos dados, transforma√ß√£o de vari√°veis, treinamento e avalia√ß√£o de modelos e tuning de hiperpar√¢metros.

## üîé An√°lise Explorat√≥ria de Dados

A an√°lise explorat√≥ria √© parte essencial de um projeto de an√°lise/ci√™ncia de dados, pois √© muito importante que voc√™ **conhe√ßa os dados que est√£o sendo trabalhados**. Isso inclui saber quais vari√°veis s√£o categ√≥ricas e quais s√£o num√©ricas, valores faltantes, duplicatas e obter insights gerais sobre as vari√°veis e caracter√≠sticas do dataset.

Minha escolha foi gerar uma **amostra simples**, na imagem abaixo isso √© exibido, assim como a reprodutibilidade dela atrav√©s do **np.random.seed**, que garante que trabalhemos sempre com a mesma amostra.

### Gera√ß√£o da amostra aleat√≥ria

O dataset trabalhado no desafio √© uma base real de dados de carros usados de um grande website da internet possuindo um n√∫mero muito grande de registros. Portanto, algo requerido para auxiliar na manipula√ß√£o do dataset e no treinamento do modelo foi a **cria√ß√£o de uma amostra aleat√≥ria reprodut√≠vel de 25% do conjunto de dados**, o que j√° √© mais que suficiente para desenvolver uma boa an√°lise.

![Evidencia](./evidencias/eda/sample.png)

### Fabricantes mais presentes no site

![Evidencia](./evidencias/eda/fabricantes%20mais%20presentes.png)

Com a vari√°vel *manufacturer* foi poss√≠vel visualizar e entender **quais s√£o os fabricantes de carros que mais est√£o presentes no dataset, ou seja, no site**. √â interessante analisar as vari√°veis pois esse entendimento pode levar a outras an√°lise dentro de cada fabricante do dataset.

### Distribui√ß√£o dos anos de fabrica√ß√£o

![Evidencia](./evidencias/eda/distribuicao_anos.png)

Ap√≥s um tratamento de outliers da vari√°vel *year* onde eu limitei os anos de fabrica√ß√£o dos carros de **2000 √† 2023**, eu obtive o gr√°fico acima. Ele n√£o indica uma distribui√ß√£o normal, mas evidencia a tend√™ncia de subida em 2017 e um pico de fabrica√ß√£o de carros no ano de 2020.

### Distribui√ß√£o de pre√ßos

![Evidencia](./evidencias/eda/distribuicao_price.png)

Ap√≥s a remo√ß√£o de outliers, o plot do histograma evidenciou que a distribui√ß√£o da vari√°vel *price* ficou bem melhor, apesar de n√£o ser normal. Ele mostra que mesmo ap√≥s a remo√ß√£o de outliers, h√° valores de price que s√£o maiores, mas em menor quantidade. Al√©m disso, o pico mais alto no histograma est√° em torno de 20.000, o que indica que existe uma **maior quantidade de carros com esse valor** na sample.


## ü§ñ Constru√ß√£o e Treinamento do Modelo

Ap√≥s todo o processo de limpeza, pr√©-processamento e transforma√ß√£o, era necess√°rio descobrir estatisticamente quais s√£o as **vari√°veis mais importantes para o treinamento de modelos**. Para isso, rodei um **RandomForestRegressor** com todas as vari√°veis para descobrir quais s√£o mais importantes.

![Evidencia](./evidencias/treinamento_modelos/feature_importance.png)

Com os resultados desse modelo treinado, fiz algumas transforma√ß√µes e obtive esse gr√°fico que exibe as **vari√°veis mais importantes de acordo com o RandomForest**.

![Evidencia](./evidencias/treinamento_modelos/feature_importance2.png)

### Treinamento

Foram realizados testes com 2 algoritmos diferentes, o **RandomForestRegressor**, um algoritmo que cira m√∫ltiplas √°rvores de decis√£o e o **LightGBM**, um algoritmo de Gradient Boosting muito eficiente para grandes bases de dados. 

Treinei 3 modelos para cada abordagem, um sem usar **nenhum tipo de normaliza√ß√£o de dados**, outro utilizando o **StandardScaler** e outro utilzando o **Min-Max Scaler**. Foi interessante observar que, como os algoritmos s√£o baseados em √°rvores e eles s√£o **invariantes √† transforma√ß√£o de dados**, os modelos que tiveram os dados escalados tiveram piores m√©tricas, portanto, n√£o utilizei nenhum tipo de normaliza√ß√£o.

### Random Forest

![Evidencia](./evidencias/treinamento_modelos/rf_train.png)

![Evidencia](./evidencias/treinamento_modelos/rf_train2.png)

### LightGBM

![Evidencia](./evidencias/treinamento_modelos/lgbm_train.png)

![Evidencia](./evidencias/treinamento_modelos/lgbm_train2.png)

### Tuning

Para melhorar essas m√©tricas, um bom caminho seria fazer o **Tuning de hiperpar√¢metros** para os modelos testados, e ele foi realizado com a ferramenta **Optuna**, onde voc√™ define uma fun√ß√£o **objective** para sugerir uma margem de valores para os hiperpar√¢metros definidos e retornar o **MAE** dos treinos realizados. Ap√≥s isso, um **study** √© criado e orientado a minimizar a m√©trica e o **optimze** roda o Tuning com a quantidade de vezes definidas pelo **n_trials**.

Depois de rodar o Tuning, com o *.best_params* voc√™ consegue visualizar a **melhor combina√ß√£o de par√¢metros** encontrada por algoritmo.

## Random Forest

![Evidencia](./evidencias/tuning/tuning_rf.png)

![Evidencia](./evidencias/tuning/tuning_rf2.png)

## LightGBM

![Evidencia](./evidencias/tuning/tuning_lgbm.png)

![Evidencia](./evidencias/tuning/tuning_lgbm2.png)

## üìù Avalia√ß√£o do Modelo e M√©tricas

Para avaliar os modelos de regress√£o, eu utilizei as m√©tricas **Mean Absolute Error(MAE)** e **Root Mean Squared Error(RMSE)**.

- O **MSE** representa os valores erro absoluto m√©dio entre as previs√µes e os valores reais.

- O **RMSE** leva em considera√ß√£o o quadrado dos erros, penalizando erros maiores de forma mais severa.

Ap√≥s a realiza√ß√£o do Tuning, os modelos foram treinados com os melhores hiperpar√¢metros, e o que teve as melhores m√©tricas foi o **LightGBM**.

### LightGBM

![Evidencia](./evidencias/avaliacao_e_metricas/lgbm_metrics.png)

### Random Forest

![Evidencia](./evidencias/avaliacao_e_metricas/random_forest_metrics.png)

## üß† Conclus√£o

Avaliando as m√©tricas, √© percept√≠vel que o **LightGBM** teve um resultado **melhor** do que o **RandomForest**, tanto para **MAE**, quanto para **RMSE**, principalmente ap√≥s o Tuning de hiperpar√¢metros. Por√©m, n√£o necessariamente a performance do modelo √© boa. Como dito anteriormente, para valores mais altos de price a diferen√ßa que pode existir na previs√£o de valores pode n√£o ser t√£o impactante por√©m, para previs√µes de carros mais baratos, a diferen√ßa pode ser mais impactante e influenciar mais na previs√£o.